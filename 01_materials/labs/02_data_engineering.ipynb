{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are we doing?\n",
    "\n",
    "## Objectives \n",
    "\n",
    "\n",
    "* Build a data pipeline that downloads price data from the internet, stores it locally, transforms it into return data, and stores the feature set.\n",
    "    - Getting the data.\n",
    "    - Schemas and index in dask.\n",
    "\n",
    "* Explore the parquet format.\n",
    "    - Reading and writing parquet files.\n",
    "    - Read datasets that are stored in distributed files.\n",
    "    - Discuss dask vs pandas as a small example of big vs small data.\n",
    "    \n",
    "* Discuss the use of environment variables for settings.\n",
    "* Discuss how to use Jupyter notebooks and source code concurrently. \n",
    "* Logging and using a standard logger.\n",
    "\n",
    "## About the Data\n",
    "\n",
    "+ We will download the prices for a list of stocks.\n",
    "+ The source is Yahoo Finance and we will use the API provided by the library yfinance.\n",
    "\n",
    "\n",
    "## Medallion Architecture\n",
    "\n",
    "+ The architecture that we are thinking about is called Medallion by [DataBricks](https://www.databricks.com/glossary/medallion-architecture). It is an ELT type of thinking, although our data is well-structured.\n",
    "\n",
    "![Medallion Architecture (DataBicks)](./images/02_medallion_architecture.png)\n",
    "\n",
    "+ In our case, we would like to optimize the number of times that we download data from the internet. \n",
    "+ Ultimately, we will build a pipeline manager class that will help us control the process of obtaining and transforming our data.\n",
    "\n",
    "![](./images/02_target_pipeline_manager.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data from Yahoo Finance\n",
    "\n",
    "Yahoo Finance provides information about public stocks in different markets. The library yfinance gives us access to a fair bit of the data in Yahoo Finance. \n",
    "\n",
    "These steps are based on the instructions in:\n",
    "\n",
    "+ [yfinance documentation](https://pypi.org/project/yfinance/)\n",
    "+ [Tutorial in geeksforgeeks.org](https://www.geeksforgeeks.org/get-financial-data-from-yahoo-finance-with-python/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ If required, install: `python -m pip install yfinance`.\n",
    "+ To download the price history of a stock, first use the following setup:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.getenv('SRC_DIR'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logger import get_logger\n",
    "_logs = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to notice in the code chunk above:\n",
    "\n",
    "+ Libraries are ordered from high-level to low-level libraries from the package manager (pip in this case, but could be conda, poetry, etc.)\n",
    "+ The command `sys.path.append(\"../05_src/)` will add the `../05_src/` directory to the path in the Notebook's kernel. This way, we can use our modules as part of the notebook.\n",
    "+ Local modules are imported at the end. \n",
    "+ The function `get_logger()` is called with `__name__` as recommended by the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to download the historical price data for a stock, we could use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = yf.Ticker(\"AAPL\")\n",
    "px = stock.history(start = \"2013-12-01\", end = \"2024-02-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-12-02 00:00:00-05:00</th>\n",
       "      <td>17.425308</td>\n",
       "      <td>17.622981</td>\n",
       "      <td>17.201090</td>\n",
       "      <td>17.213894</td>\n",
       "      <td>472544800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-03 00:00:00-05:00</th>\n",
       "      <td>17.434678</td>\n",
       "      <td>17.687002</td>\n",
       "      <td>17.415317</td>\n",
       "      <td>17.685127</td>\n",
       "      <td>450968000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-04 00:00:00-05:00</th>\n",
       "      <td>17.659515</td>\n",
       "      <td>17.774748</td>\n",
       "      <td>17.513368</td>\n",
       "      <td>17.643902</td>\n",
       "      <td>377809600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-05 00:00:00-05:00</th>\n",
       "      <td>17.882801</td>\n",
       "      <td>17.960559</td>\n",
       "      <td>17.687938</td>\n",
       "      <td>17.734467</td>\n",
       "      <td>447580000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-06 00:00:00-05:00</th>\n",
       "      <td>17.668577</td>\n",
       "      <td>17.698557</td>\n",
       "      <td>17.474339</td>\n",
       "      <td>17.488390</td>\n",
       "      <td>344352400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-25 00:00:00-05:00</th>\n",
       "      <td>194.707126</td>\n",
       "      <td>195.754371</td>\n",
       "      <td>192.602669</td>\n",
       "      <td>193.659882</td>\n",
       "      <td>54822100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26 00:00:00-05:00</th>\n",
       "      <td>193.759620</td>\n",
       "      <td>194.248323</td>\n",
       "      <td>191.435740</td>\n",
       "      <td>191.914474</td>\n",
       "      <td>44594000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-29 00:00:00-05:00</th>\n",
       "      <td>191.505551</td>\n",
       "      <td>191.695054</td>\n",
       "      <td>189.081942</td>\n",
       "      <td>191.226288</td>\n",
       "      <td>47145600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30 00:00:00-05:00</th>\n",
       "      <td>190.438365</td>\n",
       "      <td>191.296106</td>\n",
       "      <td>186.977480</td>\n",
       "      <td>187.545975</td>\n",
       "      <td>55859400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-31 00:00:00-05:00</th>\n",
       "      <td>186.548606</td>\n",
       "      <td>186.608461</td>\n",
       "      <td>183.865686</td>\n",
       "      <td>183.915543</td>\n",
       "      <td>55467800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2558 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Date                                                                        \n",
       "2013-12-02 00:00:00-05:00   17.425308   17.622981   17.201090   17.213894   \n",
       "2013-12-03 00:00:00-05:00   17.434678   17.687002   17.415317   17.685127   \n",
       "2013-12-04 00:00:00-05:00   17.659515   17.774748   17.513368   17.643902   \n",
       "2013-12-05 00:00:00-05:00   17.882801   17.960559   17.687938   17.734467   \n",
       "2013-12-06 00:00:00-05:00   17.668577   17.698557   17.474339   17.488390   \n",
       "...                               ...         ...         ...         ...   \n",
       "2024-01-25 00:00:00-05:00  194.707126  195.754371  192.602669  193.659882   \n",
       "2024-01-26 00:00:00-05:00  193.759620  194.248323  191.435740  191.914474   \n",
       "2024-01-29 00:00:00-05:00  191.505551  191.695054  189.081942  191.226288   \n",
       "2024-01-30 00:00:00-05:00  190.438365  191.296106  186.977480  187.545975   \n",
       "2024-01-31 00:00:00-05:00  186.548606  186.608461  183.865686  183.915543   \n",
       "\n",
       "                              Volume  Dividends  Stock Splits  \n",
       "Date                                                           \n",
       "2013-12-02 00:00:00-05:00  472544800        0.0           0.0  \n",
       "2013-12-03 00:00:00-05:00  450968000        0.0           0.0  \n",
       "2013-12-04 00:00:00-05:00  377809600        0.0           0.0  \n",
       "2013-12-05 00:00:00-05:00  447580000        0.0           0.0  \n",
       "2013-12-06 00:00:00-05:00  344352400        0.0           0.0  \n",
       "...                              ...        ...           ...  \n",
       "2024-01-25 00:00:00-05:00   54822100        0.0           0.0  \n",
       "2024-01-26 00:00:00-05:00   44594000        0.0           0.0  \n",
       "2024-01-29 00:00:00-05:00   47145600        0.0           0.0  \n",
       "2024-01-30 00:00:00-05:00   55859400        0.0           0.0  \n",
       "2024-01-31 00:00:00-05:00   55467800        0.0           0.0  \n",
       "\n",
       "[2558 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametrize the download\n",
    "\n",
    "+ Generally, we will look to separate every parameter and setting from functions.\n",
    "+ If we had a few stocks, we could cycle through them. We need a place to store the list of tickers (a db or file, for example).\n",
    "+ Store a csv file with a few stock tickers. The location of the file is a setting, the contents of this file are parameters.\n",
    "+ Use **environment variables** to pass parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>Security</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub-Industry</th>\n",
       "      <th>Headquarters Location</th>\n",
       "      <th>Date added</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Founded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>JCI</td>\n",
       "      <td>Johnson Controls</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Building Products</td>\n",
       "      <td>Cork, Ireland</td>\n",
       "      <td>40417</td>\n",
       "      <td>833444</td>\n",
       "      <td>1885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>BSX</td>\n",
       "      <td>Boston Scientific</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>Marlborough, Massachusetts</td>\n",
       "      <td>34754</td>\n",
       "      <td>885725</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>LIN</td>\n",
       "      <td>Linde plc</td>\n",
       "      <td>Materials</td>\n",
       "      <td>Industrial Gases</td>\n",
       "      <td>Guildford, United Kingdom</td>\n",
       "      <td>33786</td>\n",
       "      <td>1707925</td>\n",
       "      <td>1879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>DOW</td>\n",
       "      <td>Dow Inc.</td>\n",
       "      <td>Materials</td>\n",
       "      <td>Commodity Chemicals</td>\n",
       "      <td>Midland, Michigan</td>\n",
       "      <td>43556</td>\n",
       "      <td>1751788</td>\n",
       "      <td>2019 (1897)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>CVX</td>\n",
       "      <td>Chevron Corporation</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Integrated Oil &amp; Gas</td>\n",
       "      <td>San Ramon, California</td>\n",
       "      <td>20883</td>\n",
       "      <td>93410</td>\n",
       "      <td>1879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>KHC</td>\n",
       "      <td>Kraft Heinz</td>\n",
       "      <td>Consumer Staples</td>\n",
       "      <td>Packaged Foods &amp; Meats</td>\n",
       "      <td>Chicago, Illinois; Pittsburgh, Pennsylvania</td>\n",
       "      <td>42191</td>\n",
       "      <td>1637459</td>\n",
       "      <td>2015 (1869)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>RL</td>\n",
       "      <td>Ralph Lauren Corporation</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Apparel, Accessories &amp; Luxury Goods</td>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>39115</td>\n",
       "      <td>1037038</td>\n",
       "      <td>1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>ED</td>\n",
       "      <td>Consolidated Edison</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>Multi-Utilities</td>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>20883</td>\n",
       "      <td>1047862</td>\n",
       "      <td>1823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>BX</td>\n",
       "      <td>Blackstone</td>\n",
       "      <td>Financials</td>\n",
       "      <td>Asset Management &amp; Custody Banks</td>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>45187</td>\n",
       "      <td>1393818</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>IBM</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Consulting &amp; Other Services</td>\n",
       "      <td>Armonk, New York</td>\n",
       "      <td>20883</td>\n",
       "      <td>51143</td>\n",
       "      <td>1911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Life Sciences Tools &amp; Services</td>\n",
       "      <td>Santa Clara, California</td>\n",
       "      <td>36682</td>\n",
       "      <td>1090872</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>FIS</td>\n",
       "      <td>Fidelity National Information Services</td>\n",
       "      <td>Financials</td>\n",
       "      <td>Transaction &amp; Payment Processing Services</td>\n",
       "      <td>Jacksonville, Florida</td>\n",
       "      <td>39031</td>\n",
       "      <td>1136893</td>\n",
       "      <td>1968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>MAS</td>\n",
       "      <td>Masco</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Building Products</td>\n",
       "      <td>Livonia, Michigan</td>\n",
       "      <td>29767</td>\n",
       "      <td>62996</td>\n",
       "      <td>1929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>CPB</td>\n",
       "      <td>Campbell Soup Company</td>\n",
       "      <td>Consumer Staples</td>\n",
       "      <td>Packaged Foods &amp; Meats</td>\n",
       "      <td>Camden, New Jersey</td>\n",
       "      <td>20883</td>\n",
       "      <td>16732</td>\n",
       "      <td>1869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>PNW</td>\n",
       "      <td>Pinnacle West</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>Multi-Utilities</td>\n",
       "      <td>Phoenix, Arizona</td>\n",
       "      <td>36437</td>\n",
       "      <td>764622</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>QCOM</td>\n",
       "      <td>Qualcomm</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Semiconductors</td>\n",
       "      <td>San Diego, California</td>\n",
       "      <td>36363</td>\n",
       "      <td>804328</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>YUM</td>\n",
       "      <td>Yum! Brands</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Louisville, Kentucky</td>\n",
       "      <td>35709</td>\n",
       "      <td>1041061</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>AWK</td>\n",
       "      <td>American Water Works</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>Water Utilities</td>\n",
       "      <td>Camden, New Jersey</td>\n",
       "      <td>42433</td>\n",
       "      <td>1410636</td>\n",
       "      <td>1886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>MU</td>\n",
       "      <td>Micron Technology</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Semiconductors</td>\n",
       "      <td>Boise, Idaho</td>\n",
       "      <td>34604</td>\n",
       "      <td>723125</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>RCL</td>\n",
       "      <td>Royal Caribbean Group</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Hotels, Resorts &amp; Cruise Lines</td>\n",
       "      <td>Miami, Florida</td>\n",
       "      <td>41978</td>\n",
       "      <td>884887</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>WTW</td>\n",
       "      <td>Willis Towers Watson</td>\n",
       "      <td>Financials</td>\n",
       "      <td>Insurance Brokers</td>\n",
       "      <td>London, United Kingdom</td>\n",
       "      <td>42374</td>\n",
       "      <td>1140536</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>GWW</td>\n",
       "      <td>W. W. Grainger</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Machinery &amp; Supplies &amp; Components</td>\n",
       "      <td>Lake Forest, Illinois</td>\n",
       "      <td>29767</td>\n",
       "      <td>277135</td>\n",
       "      <td>1927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>HAS</td>\n",
       "      <td>Hasbro</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Leisure Products</td>\n",
       "      <td>Pawtucket, Rhode Island</td>\n",
       "      <td>30955</td>\n",
       "      <td>46080</td>\n",
       "      <td>1923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>PEAK</td>\n",
       "      <td>Healthpeak</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Health Care REITs</td>\n",
       "      <td>Long Beach, California</td>\n",
       "      <td>39538</td>\n",
       "      <td>765880</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>BR</td>\n",
       "      <td>Broadridge Financial Solutions</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Data Processing &amp; Outsourced Services</td>\n",
       "      <td>Lake Success, New York</td>\n",
       "      <td>43269</td>\n",
       "      <td>1383312</td>\n",
       "      <td>1962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>VLO</td>\n",
       "      <td>Valero Energy</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Oil &amp; Gas Refining &amp; Marketing</td>\n",
       "      <td>San Antonio, Texas</td>\n",
       "      <td>37610</td>\n",
       "      <td>1035002</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>VICI</td>\n",
       "      <td>Vici Properties</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Hotel &amp; Resort REITs</td>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>44720</td>\n",
       "      <td>1705696</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>RHI</td>\n",
       "      <td>Robert Half</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Human Resource &amp; Employment Services</td>\n",
       "      <td>Menlo Park, California</td>\n",
       "      <td>36865</td>\n",
       "      <td>315213</td>\n",
       "      <td>1948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>CRL</td>\n",
       "      <td>Charles River Laboratories</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Life Sciences Tools &amp; Services</td>\n",
       "      <td>Wilmington, Massachusetts</td>\n",
       "      <td>44330</td>\n",
       "      <td>1100682</td>\n",
       "      <td>1947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>NEM</td>\n",
       "      <td>Newmont</td>\n",
       "      <td>Materials</td>\n",
       "      <td>Gold</td>\n",
       "      <td>Denver, Colorado</td>\n",
       "      <td>25384</td>\n",
       "      <td>1164727</td>\n",
       "      <td>1921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>LYB</td>\n",
       "      <td>LyondellBasell</td>\n",
       "      <td>Materials</td>\n",
       "      <td>Specialty Chemicals</td>\n",
       "      <td>Rotterdam, Netherlands</td>\n",
       "      <td>41157</td>\n",
       "      <td>1489393</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>GS</td>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>Financials</td>\n",
       "      <td>Investment Banking &amp; Brokerage</td>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>37459</td>\n",
       "      <td>886982</td>\n",
       "      <td>1869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>V</td>\n",
       "      <td>Visa Inc.</td>\n",
       "      <td>Financials</td>\n",
       "      <td>Transaction &amp; Payment Processing Services</td>\n",
       "      <td>San Francisco, California</td>\n",
       "      <td>40168</td>\n",
       "      <td>1403161</td>\n",
       "      <td>1958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>EPAM</td>\n",
       "      <td>EPAM Systems</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Consulting &amp; Other Services</td>\n",
       "      <td>Newtown, Pennsylvania</td>\n",
       "      <td>44544</td>\n",
       "      <td>1352010</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>20883</td>\n",
       "      <td>1800</td>\n",
       "      <td>1888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>Movies &amp; Entertainment</td>\n",
       "      <td>Los Gatos, California</td>\n",
       "      <td>40532</td>\n",
       "      <td>1065280</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>KVUE</td>\n",
       "      <td>Kenvue</td>\n",
       "      <td>Consumer Staples</td>\n",
       "      <td>Personal Care Products</td>\n",
       "      <td>Skillman, New Jersey</td>\n",
       "      <td>45163</td>\n",
       "      <td>1944048</td>\n",
       "      <td>2022 (Johnson &amp; Johnson spinoff)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>BKNG</td>\n",
       "      <td>Booking Holdings</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Hotels, Resorts &amp; Cruise Lines</td>\n",
       "      <td>Norwalk, Connecticut</td>\n",
       "      <td>40123</td>\n",
       "      <td>1075531</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>IT</td>\n",
       "      <td>Gartner</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Consulting &amp; Other Services</td>\n",
       "      <td>Stamford, Connecticut</td>\n",
       "      <td>42830</td>\n",
       "      <td>749251</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>BBY</td>\n",
       "      <td>Best Buy</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Computer &amp; Electronics Retail</td>\n",
       "      <td>Richfield, Minnesota</td>\n",
       "      <td>36340</td>\n",
       "      <td>764478</td>\n",
       "      <td>1966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>NUE</td>\n",
       "      <td>Nucor</td>\n",
       "      <td>Materials</td>\n",
       "      <td>Steel</td>\n",
       "      <td>Charlotte, North Carolina</td>\n",
       "      <td>31167</td>\n",
       "      <td>73309</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>CBRE</td>\n",
       "      <td>CBRE Group</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Real Estate Services</td>\n",
       "      <td>Dallas, Texas</td>\n",
       "      <td>39031</td>\n",
       "      <td>1138118</td>\n",
       "      <td>1906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>WDC</td>\n",
       "      <td>Western Digital</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Technology Hardware, Storage &amp; Peripherals</td>\n",
       "      <td>San Jose, California</td>\n",
       "      <td>39995</td>\n",
       "      <td>106040</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>EXPE</td>\n",
       "      <td>Expedia Group</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Hotels, Resorts &amp; Cruise Lines</td>\n",
       "      <td>Seattle, Washington</td>\n",
       "      <td>39357</td>\n",
       "      <td>1324424</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>AMGN</td>\n",
       "      <td>Amgen</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Biotechnology</td>\n",
       "      <td>Thousand Oaks, California</td>\n",
       "      <td>33605</td>\n",
       "      <td>318154</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>BRO</td>\n",
       "      <td>Brown &amp; Brown</td>\n",
       "      <td>Financials</td>\n",
       "      <td>Insurance Brokers</td>\n",
       "      <td>Daytona Beach, Florida</td>\n",
       "      <td>44459</td>\n",
       "      <td>79282</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "      <td>Saint Paul, Minnesota</td>\n",
       "      <td>20883</td>\n",
       "      <td>66740</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ABNB</td>\n",
       "      <td>Airbnb</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Hotels, Resorts &amp; Cruise Lines</td>\n",
       "      <td>San Francisco, California</td>\n",
       "      <td>45187</td>\n",
       "      <td>1559720</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>MDT</td>\n",
       "      <td>Medtronic</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>31716</td>\n",
       "      <td>1613103</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Broadline Retail</td>\n",
       "      <td>Seattle, Washington</td>\n",
       "      <td>38674</td>\n",
       "      <td>1018724</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker                                Security             GICS Sector  \\\n",
       "268    JCI                        Johnson Controls             Industrials   \n",
       "73     BSX                       Boston Scientific             Health Care   \n",
       "289    LIN                               Linde plc               Materials   \n",
       "155    DOW                                Dow Inc.               Materials   \n",
       "104    CVX                     Chevron Corporation                  Energy   \n",
       "280    KHC                             Kraft Heinz        Consumer Staples   \n",
       "392     RL                Ralph Lauren Corporation  Consumer Discretionary   \n",
       "124     ED                     Consolidated Edison               Utilities   \n",
       "68      BX                              Blackstone              Financials   \n",
       "244    IBM                                     IBM  Information Technology   \n",
       "9        A                    Agilent Technologies             Health Care   \n",
       "195    FIS  Fidelity National Information Services              Financials   \n",
       "304    MAS                                   Masco             Industrials   \n",
       "84     CPB                   Campbell Soup Company        Consumer Staples   \n",
       "373    PNW                           Pinnacle West               Utilities   \n",
       "390   QCOM                                Qualcomm  Information Technology   \n",
       "498    YUM                             Yum! Brands  Consumer Discretionary   \n",
       "30     AWK                    American Water Works               Utilities   \n",
       "317     MU                       Micron Technology  Information Technology   \n",
       "407    RCL                   Royal Caribbean Group  Consumer Discretionary   \n",
       "493    WTW                    Willis Towers Watson              Financials   \n",
       "494    GWW                          W. W. Grainger             Industrials   \n",
       "225    HAS                                  Hasbro  Consumer Discretionary   \n",
       "227   PEAK                              Healthpeak             Real Estate   \n",
       "76      BR          Broadridge Financial Solutions             Industrials   \n",
       "464    VLO                           Valero Energy                  Energy   \n",
       "473   VICI                         Vici Properties             Real Estate   \n",
       "402    RHI                             Robert Half             Industrials   \n",
       "101    CRL              Charles River Laboratories             Health Care   \n",
       "335    NEM                                 Newmont               Materials   \n",
       "296    LYB                          LyondellBasell               Materials   \n",
       "222     GS                           Goldman Sachs              Financials   \n",
       "474      V                               Visa Inc.              Financials   \n",
       "173   EPAM                            EPAM Systems  Information Technology   \n",
       "2      ABT                                  Abbott             Health Care   \n",
       "334   NFLX                                 Netflix  Communication Services   \n",
       "272   KVUE                                  Kenvue        Consumer Staples   \n",
       "70    BKNG                        Booking Holdings  Consumer Discretionary   \n",
       "210     IT                                 Gartner  Information Technology   \n",
       "63     BBY                                Best Buy  Consumer Discretionary   \n",
       "347    NUE                                   Nucor               Materials   \n",
       "93    CBRE                              CBRE Group             Real Estate   \n",
       "488    WDC                         Western Digital  Information Technology   \n",
       "185   EXPE                           Expedia Group  Consumer Discretionary   \n",
       "33    AMGN                                   Amgen             Health Care   \n",
       "77     BRO                           Brown & Brown              Financials   \n",
       "0      MMM                                      3M             Industrials   \n",
       "11    ABNB                                  Airbnb  Consumer Discretionary   \n",
       "310    MDT                               Medtronic             Health Care   \n",
       "22    AMZN                                  Amazon  Consumer Discretionary   \n",
       "\n",
       "                                GICS Sub-Industry  \\\n",
       "268                             Building Products   \n",
       "73                          Health Care Equipment   \n",
       "289                              Industrial Gases   \n",
       "155                           Commodity Chemicals   \n",
       "104                          Integrated Oil & Gas   \n",
       "280                        Packaged Foods & Meats   \n",
       "392           Apparel, Accessories & Luxury Goods   \n",
       "124                               Multi-Utilities   \n",
       "68               Asset Management & Custody Banks   \n",
       "244                IT Consulting & Other Services   \n",
       "9                  Life Sciences Tools & Services   \n",
       "195     Transaction & Payment Processing Services   \n",
       "304                             Building Products   \n",
       "84                         Packaged Foods & Meats   \n",
       "373                               Multi-Utilities   \n",
       "390                                Semiconductors   \n",
       "498                                   Restaurants   \n",
       "30                                Water Utilities   \n",
       "317                                Semiconductors   \n",
       "407                Hotels, Resorts & Cruise Lines   \n",
       "493                             Insurance Brokers   \n",
       "494  Industrial Machinery & Supplies & Components   \n",
       "225                              Leisure Products   \n",
       "227                             Health Care REITs   \n",
       "76          Data Processing & Outsourced Services   \n",
       "464                Oil & Gas Refining & Marketing   \n",
       "473                          Hotel & Resort REITs   \n",
       "402          Human Resource & Employment Services   \n",
       "101                Life Sciences Tools & Services   \n",
       "335                                          Gold   \n",
       "296                           Specialty Chemicals   \n",
       "222                Investment Banking & Brokerage   \n",
       "474     Transaction & Payment Processing Services   \n",
       "173                IT Consulting & Other Services   \n",
       "2                           Health Care Equipment   \n",
       "334                        Movies & Entertainment   \n",
       "272                        Personal Care Products   \n",
       "70                 Hotels, Resorts & Cruise Lines   \n",
       "210                IT Consulting & Other Services   \n",
       "63                  Computer & Electronics Retail   \n",
       "347                                         Steel   \n",
       "93                           Real Estate Services   \n",
       "488    Technology Hardware, Storage & Peripherals   \n",
       "185                Hotels, Resorts & Cruise Lines   \n",
       "33                                  Biotechnology   \n",
       "77                              Insurance Brokers   \n",
       "0                        Industrial Conglomerates   \n",
       "11                 Hotels, Resorts & Cruise Lines   \n",
       "310                         Health Care Equipment   \n",
       "22                               Broadline Retail   \n",
       "\n",
       "                           Headquarters Location  Date added      CIK  \\\n",
       "268                                Cork, Ireland       40417   833444   \n",
       "73                    Marlborough, Massachusetts       34754   885725   \n",
       "289                    Guildford, United Kingdom       33786  1707925   \n",
       "155                            Midland, Michigan       43556  1751788   \n",
       "104                        San Ramon, California       20883    93410   \n",
       "280  Chicago, Illinois; Pittsburgh, Pennsylvania       42191  1637459   \n",
       "392                      New York City, New York       39115  1037038   \n",
       "124                      New York City, New York       20883  1047862   \n",
       "68                       New York City, New York       45187  1393818   \n",
       "244                             Armonk, New York       20883    51143   \n",
       "9                        Santa Clara, California       36682  1090872   \n",
       "195                        Jacksonville, Florida       39031  1136893   \n",
       "304                            Livonia, Michigan       29767    62996   \n",
       "84                            Camden, New Jersey       20883    16732   \n",
       "373                             Phoenix, Arizona       36437   764622   \n",
       "390                        San Diego, California       36363   804328   \n",
       "498                         Louisville, Kentucky       35709  1041061   \n",
       "30                            Camden, New Jersey       42433  1410636   \n",
       "317                                 Boise, Idaho       34604   723125   \n",
       "407                               Miami, Florida       41978   884887   \n",
       "493                       London, United Kingdom       42374  1140536   \n",
       "494                        Lake Forest, Illinois       29767   277135   \n",
       "225                      Pawtucket, Rhode Island       30955    46080   \n",
       "227                       Long Beach, California       39538   765880   \n",
       "76                        Lake Success, New York       43269  1383312   \n",
       "464                           San Antonio, Texas       37610  1035002   \n",
       "473                      New York City, New York       44720  1705696   \n",
       "402                       Menlo Park, California       36865   315213   \n",
       "101                    Wilmington, Massachusetts       44330  1100682   \n",
       "335                             Denver, Colorado       25384  1164727   \n",
       "296                       Rotterdam, Netherlands       41157  1489393   \n",
       "222                      New York City, New York       37459   886982   \n",
       "474                    San Francisco, California       40168  1403161   \n",
       "173                        Newtown, Pennsylvania       44544  1352010   \n",
       "2                        North Chicago, Illinois       20883     1800   \n",
       "334                        Los Gatos, California       40532  1065280   \n",
       "272                         Skillman, New Jersey       45163  1944048   \n",
       "70                          Norwalk, Connecticut       40123  1075531   \n",
       "210                        Stamford, Connecticut       42830   749251   \n",
       "63                          Richfield, Minnesota       36340   764478   \n",
       "347                    Charlotte, North Carolina       31167    73309   \n",
       "93                                 Dallas, Texas       39031  1138118   \n",
       "488                         San Jose, California       39995   106040   \n",
       "185                          Seattle, Washington       39357  1324424   \n",
       "33                     Thousand Oaks, California       33605   318154   \n",
       "77                        Daytona Beach, Florida       44459    79282   \n",
       "0                          Saint Paul, Minnesota       20883    66740   \n",
       "11                     San Francisco, California       45187  1559720   \n",
       "310                              Dublin, Ireland       31716  1613103   \n",
       "22                           Seattle, Washington       38674  1018724   \n",
       "\n",
       "                              Founded  \n",
       "268                              1885  \n",
       "73                               1979  \n",
       "289                              1879  \n",
       "155                       2019 (1897)  \n",
       "104                              1879  \n",
       "280                       2015 (1869)  \n",
       "392                              1967  \n",
       "124                              1823  \n",
       "68                               1985  \n",
       "244                              1911  \n",
       "9                                1999  \n",
       "195                              1968  \n",
       "304                              1929  \n",
       "84                               1869  \n",
       "373                              1985  \n",
       "390                              1985  \n",
       "498                              1997  \n",
       "30                               1886  \n",
       "317                              1978  \n",
       "407                              1997  \n",
       "493                              2016  \n",
       "494                              1927  \n",
       "225                              1923  \n",
       "227                              1985  \n",
       "76                               1962  \n",
       "464                              1980  \n",
       "473                              2017  \n",
       "402                              1948  \n",
       "101                              1947  \n",
       "335                              1921  \n",
       "296                              2007  \n",
       "222                              1869  \n",
       "474                              1958  \n",
       "173                              1993  \n",
       "2                                1888  \n",
       "334                              1997  \n",
       "272  2022 (Johnson & Johnson spinoff)  \n",
       "70                               1996  \n",
       "210                              1979  \n",
       "63                               1966  \n",
       "347                              1940  \n",
       "93                               1906  \n",
       "488                              1970  \n",
       "185                              1996  \n",
       "33                               1980  \n",
       "77                               1939  \n",
       "0                                1902  \n",
       "11                               2008  \n",
       "310                              1949  \n",
       "22                               1994  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_file = os.getenv(\"TICKERS\")\n",
    "tickers = pd.read_csv(ticker_file).sample(50, random_state=42)\n",
    "tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting padas data frames\n",
    "\n",
    "+ From the [documentation](https://pandas.pydata.org/docs/user_guide/merging.html):\n",
    "\n",
    "> [`concat()`](https://pandas.pydata.org/docs/reference/api/pandas.concat.html#pandas.concat) makes a full copy of the data, and iteratively reusing `concat()` can create unnecessary copies. Collect all DataFrame or Series objects in a list before using `concat()`.\n",
    "\n",
    "+ We can string operation togethers using dot operations. Enclose the line in parenthesis and add linebreaks for readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing JCI\n",
      "Downloaded (2558, 9).\n",
      "Processing BSX\n",
      "Downloaded (2558, 9).\n",
      "Processing LIN\n",
      "Downloaded (2558, 9).\n",
      "Processing DOW\n",
      "Downloaded (1226, 9).\n",
      "Processing CVX\n",
      "Downloaded (2558, 9).\n",
      "Processing KHC\n",
      "Downloaded (2159, 9).\n",
      "Processing RL\n",
      "Downloaded (2558, 9).\n",
      "Processing ED\n",
      "Downloaded (2558, 9).\n",
      "Processing BX\n",
      "Downloaded (2558, 9).\n",
      "Processing IBM\n",
      "Downloaded (2558, 9).\n",
      "Processing A\n",
      "Downloaded (2558, 9).\n",
      "Processing FIS\n",
      "Downloaded (2558, 9).\n",
      "Processing MAS\n",
      "Downloaded (2558, 9).\n",
      "Processing CPB\n",
      "Downloaded (2558, 9).\n",
      "Processing PNW\n",
      "Downloaded (2558, 9).\n",
      "Processing QCOM\n",
      "Downloaded (2558, 9).\n",
      "Processing YUM\n",
      "Downloaded (2558, 9).\n",
      "Processing AWK\n",
      "Downloaded (2558, 9).\n",
      "Processing MU\n",
      "Downloaded (2558, 9).\n",
      "Processing RCL\n",
      "Downloaded (2558, 9).\n",
      "Processing WTW\n",
      "Downloaded (2558, 9).\n",
      "Processing GWW\n",
      "Downloaded (2558, 9).\n",
      "Processing HAS\n",
      "Downloaded (2558, 9).\n",
      "Processing PEAK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PEAK: No timezone found, symbol may be delisted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for PEAK\n",
      "Processing BR\n",
      "Downloaded (2558, 9).\n",
      "Processing VLO\n",
      "Downloaded (2558, 9).\n",
      "Processing VICI\n",
      "Downloaded (1530, 9).\n",
      "Processing RHI\n",
      "Downloaded (2558, 9).\n",
      "Processing CRL\n",
      "Downloaded (2558, 9).\n",
      "Processing NEM\n",
      "Downloaded (2558, 9).\n",
      "Processing LYB\n",
      "Downloaded (2558, 9).\n",
      "Processing GS\n",
      "Downloaded (2558, 9).\n",
      "Processing V\n",
      "Downloaded (2558, 9).\n",
      "Processing EPAM\n",
      "Downloaded (2558, 9).\n",
      "Processing ABT\n",
      "Downloaded (2558, 9).\n",
      "Processing NFLX\n",
      "Downloaded (2558, 9).\n",
      "Processing KVUE\n",
      "Downloaded (187, 9).\n",
      "Processing BKNG\n",
      "Downloaded (2558, 9).\n",
      "Processing IT\n",
      "Downloaded (2558, 9).\n",
      "Processing BBY\n",
      "Downloaded (2558, 9).\n",
      "Processing NUE\n",
      "Downloaded (2558, 9).\n",
      "Processing CBRE\n",
      "Downloaded (2558, 9).\n",
      "Processing WDC\n",
      "Downloaded (2558, 9).\n",
      "Processing EXPE\n",
      "Downloaded (2558, 9).\n",
      "Processing AMGN\n",
      "Downloaded (2558, 9).\n",
      "Processing BRO\n",
      "Downloaded (2558, 9).\n",
      "Processing MMM\n",
      "Downloaded (2558, 9).\n",
      "Processing ABNB\n",
      "Downloaded (789, 9).\n",
      "Processing MDT\n",
      "Downloaded (2558, 9).\n",
      "Processing AMZN\n",
      "Downloaded (2558, 9).\n",
      "Final shape (118443, 9).\n"
     ]
    }
   ],
   "source": [
    "# List to hold final results\n",
    "px_list = list()\n",
    "\n",
    "for k, row in tickers.iterrows():  # Produces an iterator that returns index and row\n",
    "\n",
    "    stock = yf.Ticker(row['ticker'])\n",
    "    print(f'Processing {row[\"ticker\"]}')\n",
    "    \n",
    "    px = (stock\n",
    "          .history(start = pd.to_datetime(\"2013-12-01\"), \n",
    "                   end = pd.to_datetime(\"2024-02-01\"))\n",
    "          .reset_index()   # Reset index to get date as a column\n",
    "          .assign(ticker = row['ticker']))    # Add ticker\n",
    "    \n",
    "    if px.shape[0] == 0:\n",
    "        print(f'No data for {row[\"ticker\"]}')  # Validate: do not fail silently.\n",
    "        continue\n",
    "    print(f'Downloaded {px.shape}.')\n",
    "    px_list.append(px)\n",
    "px_dt = pd.concat(px_list, axis = 0)\n",
    "print(f'Final shape {px_dt.shape}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reliability\n",
    "\n",
    "+ Keppelman (2017) defines *reliability* as:\n",
    "\n",
    "    - A system should continue to work correctly. \n",
    "    - To work correctly means performing the correct function at the desired level of performance, even in the face of adversity such as hardware or software faults, and even human error. \n",
    "\n",
    "+ *Faults* are things that can go wrong.\n",
    "+ Sytems that can cope with (certain types of) faults are called *fault-tolerant* or *resilient*.\n",
    "+ A fault is different than a failure. \n",
    "    \n",
    "    - A *fault* occurs when a component of the system deviates from spec.\n",
    "    - A *failure*  is when the system stops providing the required service to the user.\n",
    "\n",
    "+ In our simple example, we handle the fault that occurs when one ticker is not found and log it using *warning*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Data in CSV\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ We have some data. How do we store it?\n",
    "+ We can compare two options, CSV and Parqruet, by measuring their performance:\n",
    "\n",
    "    - Time to save.\n",
    "    - Space required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dir_size(path='.'):\n",
    "    '''Returns the total size of files contained in path.'''\n",
    "    total = 0\n",
    "    with os.scandir(path) as it:\n",
    "        for entry in it:\n",
    "            if entry.is_file():\n",
    "                total += entry.stat().st_size\n",
    "            elif entry.is_dir():\n",
    "                total += get_dir_size(entry.path)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = os.getenv(\"TEMP_DATA\")\n",
    "os.makedirs(temp, exist_ok=True)\n",
    "stock_path = os.path.join(temp, \"stock_px.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to dt ((118443, 9))csv took 0.8618819713592529 seconds.\n",
      "Csv file size 14.032497999999999 MB\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "px_dt.to_csv(stock_path, index = False)\n",
    "end = time.time()\n",
    "\n",
    "print(f'Writing to dt ({px_dt.shape})csv took {end - start} seconds.')\n",
    "print(f'Csv file size { os.path.getsize(stock_path)*1e-6 } MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data to Parquet\n",
    "\n",
    "### Dask \n",
    "\n",
    "We can work with with large data sets and parquet files. In fact, recent versions of pandas support pyarrow data types and future versions will require a pyarrow backend. The pyarrow library is an interface between Python and the Appache Arrow project. The [parquet data format](https://parquet.apache.org/) and [Arrow](https://arrow.apache.org/docs/python/parquet.html) are projects of the Apache Foundation.\n",
    "\n",
    "However, Dask is much more than an interface to Arrow: Dask provides parallel and distributed computing on pandas-like dataframes. It is also relatively easy to use, bridging a gap between pandas and Spark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "stat: path should be string, bytes, os.PathLike or integer, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdd\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/dask/dataframe/__init__.py:100\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pyarrow_compat\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backends, dispatch, rolling\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    102\u001b[0m     DataFrame,\n\u001b[1;32m    103\u001b[0m     Index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m     to_timedelta,\n\u001b[1;32m    110\u001b[0m )\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Aggregation\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/dask/dataframe/backends.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_scalar, union_categoricals\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Array\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdispatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m percentile_lookup\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpercentile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _percentile\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/dask/array/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backends, fft, lib, linalg, ma, overlap, random\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblockwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m atop, blockwise\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunk_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_chunk_type\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/dask/array/backends.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m chunk\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Array\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdispatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     concatenate_lookup,\n\u001b[1;32m     11\u001b[0m     divide_lookup,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     to_numpy_dispatch,\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m divide \u001b[38;5;28;01mas\u001b[39;00m np_divide\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/dask/array/core.py:63\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhighlevelgraph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HighLevelGraph, MaterializedLayer\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArraySliceDep, reshapelist\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msizeof\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sizeof\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Graph, Key, NestedKeys\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     66\u001b[0m     IndexCallable,\n\u001b[1;32m     67\u001b[0m     SerializableLock,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m     typename,\n\u001b[1;32m     85\u001b[0m )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/dask/sizeof.py:273\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m             logger\u001b[38;5;241m.\u001b[39mexception(\n\u001b[1;32m    269\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to register sizeof entry point \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mentry_point\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    270\u001b[0m             )\n\u001b[0;32m--> 273\u001b[0m \u001b[43m_register_entry_point_plugins\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/dask/sizeof.py:263\u001b[0m, in \u001b[0;36m_register_entry_point_plugins\u001b[0;34m()\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_register_entry_point_plugins\u001b[39m():\n\u001b[1;32m    262\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Register sizeof implementations exposed by the entry_point mechanism.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m entry_point \u001b[38;5;129;01min\u001b[39;00m \u001b[43mimportlib_metadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentry_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdask.sizeof\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    264\u001b[0m         registrar \u001b[38;5;241m=\u001b[39m entry_point\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/importlib_metadata/__init__.py:1020\u001b[0m, in \u001b[0;36mentry_points\u001b[0;34m(**params)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return EntryPoint objects for all installed packages.\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \n\u001b[1;32m   1011\u001b[0m \u001b[38;5;124;03mPass selection parameters (group or name) to filter the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;124;03m:return: EntryPoints for all installed packages.\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m eps \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m   1018\u001b[0m     dist\u001b[38;5;241m.\u001b[39mentry_points \u001b[38;5;28;01mfor\u001b[39;00m dist \u001b[38;5;129;01min\u001b[39;00m _unique(distributions())\n\u001b[1;32m   1019\u001b[0m )\n\u001b[0;32m-> 1020\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mEntryPoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/importlib_metadata/__init__.py:1017\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mentry_points\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m EntryPoints:\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return EntryPoint objects for all installed packages.\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \n\u001b[1;32m   1011\u001b[0m \u001b[38;5;124;03m    Pass selection parameters (group or name) to filter the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;124;03m    :return: EntryPoints for all installed packages.\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1017\u001b[0m     eps \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m   1018\u001b[0m         dist\u001b[38;5;241m.\u001b[39mentry_points \u001b[38;5;28;01mfor\u001b[39;00m dist \u001b[38;5;129;01min\u001b[39;00m _unique(distributions())\n\u001b[1;32m   1019\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m EntryPoints(eps)\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/importlib_metadata/_itertools.py:15\u001b[0m, in \u001b[0;36munique_everseen\u001b[0;34m(iterable, key)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m element\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m     16\u001b[0m         k \u001b[38;5;241m=\u001b[39m key(element)\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m seen:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/importlib_metadata/__init__.py:900\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Find metadata directories in paths heuristically.\"\"\"\u001b[39;00m\n\u001b[1;32m    898\u001b[0m prepared \u001b[38;5;241m=\u001b[39m Prepared(name)\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m--> 900\u001b[0m     \u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprepared\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(FastPath, paths)\n\u001b[1;32m    901\u001b[0m )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/importlib_metadata/__init__.py:759\u001b[0m, in \u001b[0;36mFastPath.search\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[0;32m--> 759\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlookup(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmtime\u001b[49m)\u001b[38;5;241m.\u001b[39msearch(name)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/importlib_metadata/__init__.py:764\u001b[0m, in \u001b[0;36mFastPath.mtime\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmtime\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(\u001b[38;5;167;01mOSError\u001b[39;00m):\n\u001b[0;32m--> 764\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mst_mtime\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlookup\u001b[38;5;241m.\u001b[39mcache_clear()\n",
      "\u001b[0;31mTypeError\u001b[0m: stat: path should be string, bytes, os.PathLike or integer, not NoneType"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m px_dd \u001b[38;5;241m=\u001b[39m \u001b[43mdd\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pandas(px_dt, npartitions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(tickers))\n\u001b[1;32m      2\u001b[0m parquet_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(temp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstock_px.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dd' is not defined"
     ]
    }
   ],
   "source": [
    "px_dd = dd.from_pandas(px_dt, npartitions = len(tickers))\n",
    "parquet_path = os.path.join(temp, \"stock_px.parquet\")\n",
    "\n",
    "start = time.time()\n",
    "px_dd.to_parquet(parquet_path, engine = \"pyarrow\")\n",
    "end = time.time()\n",
    "\n",
    "print(f'Writing dd ({px_dt.shape}) to parquet took {end - start} seconds.')\n",
    "print(f'Parquet file size { get_dir_size(parquet_path)*1e-6 } MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parquet files and Dask Dataframes\n",
    "\n",
    "+ Parquet files are immutable: once written, they cannot be modified.\n",
    "+ Dask DataFrames are a useful implementation to manipulate data stored in parquets.\n",
    "+ Parquet and Dask are not the same: parquet is a file format that can be accessed by many applications and programming languages (Python, R, PowerBI, etc.), while Dask is a package in Python to work with large datasets using distributed computation.\n",
    "+ **Dask is not for everything** (see [Dask DataFrames Best Practices](https://docs.dask.org/en/stable/dataframe-best-practices.html)). \n",
    "\n",
    "    - Consider cases suchas small to larrge joins, where the small dataframe fits in memory, but the large one does not. \n",
    "    - If possible, use pandas: reduce, then use pandas.\n",
    "    - Pandas performance tips apply to Dask.\n",
    "    - Use the index: it is beneficial to have a well-defined index in Dask DataFrames, as it may speed up searching (filtering) the data. A one-dimensional index is allowed.\n",
    "    - Avoid (or minimize) full-data shuffling: indexing is an expensive operations. \n",
    "    - Some joins are more expensive than others. \n",
    "\n",
    "        * Not expensive:\n",
    "\n",
    "            - Join a Dask DataFrame with a pandas DataFrame.\n",
    "            - Join a Dask DataFrame with another Dask DataFrame of a single partition.\n",
    "            - Join Dask DataFrames along their indexes.\n",
    "\n",
    "        * Expensive:\n",
    "\n",
    "            - Join Dask DataFrames along columns that are not their index.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do we store prices?\n",
    "\n",
    "+ We can store our data as a single blob. This can be difficult to maintain, especially because parquet files are immutable.\n",
    "+ Strategy: organize data files by ticker and date. Update only latest month.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLean up before start\n",
    "PRICE_DATA = os.getenv(\"PRICE_DATA\")\n",
    "import shutil\n",
    "if os.path.exists(PRICE_DATA):\n",
    "    shutil.rmtree(PRICE_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in px_dt.ticker.unique():\n",
    "    ticker_dt = px_dt[px_dt.ticker == ticker]\n",
    "    ticker_dt = ticker_dt.assign(year = ticker_dt.Date.dt.year)\n",
    "    for yr in ticker_dt.year.unique():\n",
    "        yr_dt = ticker_dt[ticker_dt.year == yr]\n",
    "        yr_path = os.path.join(PRICE_DATA, ticker, f\"{ticker}_{yr}.parquet\")\n",
    "        os.makedirs(os.path.dirname(yr_path), exist_ok=True)\n",
    "        yr_dt.to_parquet(yr_path, engine = \"pyarrow\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why would we want to store data this way?\n",
    "\n",
    "+ Easier to maintain. We do not update old data, only recent data.\n",
    "+ We can also access all files as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load, Transform and Save "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "\n",
    "+ Parquet files can be read individually or as a collection.\n",
    "+ `dd.read_parquet()` can take a list (collection) of files as input.\n",
    "+ Use `glob` to get the collection of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "parquet_files = glob(os.path.join(PRICE_DATA, \"*/*.parquet\"))\n",
    "dd_px = dd.read_parquet(parquet_files).set_index(\"ticker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n",
    "\n",
    "+ This transformation step will create a *Features* data set. In our case, features will be stock returns (we obtained prices).\n",
    "+ Dask dataframes work like pandas dataframes: in particular, we can perform groupby and apply operations.\n",
    "+ Notice the use of [an anonymous (lambda) function](https://realpython.com/python-lambda/) in the apply statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dd_rets = (dd_px.groupby('ticker', group_keys=False).apply(\n",
    "    lambda x: x.assign(Close_lag_1 = x['Close'].shift(1))\n",
    ").assign(\n",
    "    returns = lambda x: x['Close']/x['Close_lag_1'] - 1\n",
    ").assign(\n",
    "    positive_return = lambda x: (x['returns'] > 0)*1\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy Exection\n",
    "\n",
    "What does `dd_rets` contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_rets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Dask is a lazy execution framework: commands will not execute until they are required. \n",
    "+ To trigger an execution in dask use `.compute()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_rets.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save\n",
    "\n",
    "+ Apply transformations to calculate daily returns\n",
    "+ Store the enriched data, the silver dataset, in a new directory.\n",
    "+ Should we keep the same namespace? All columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLean up before start\n",
    "FEATURES_DATA = os.getenv(\"FEATURES_DATA\")\n",
    "if os.path.exists(FEATURES_DATA):\n",
    "    shutil.rmtree(FEATURES_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_DATA = os.getenv(\"FEATURES_DATA\")\n",
    "dd_rets.to_parquet(FEATURES_DATA, engine = \"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A few notes\n",
    "\n",
    "# Jupyter? \n",
    "\n",
    "+ We have drafted our code in a Jupyter Notebook. \n",
    "+ Finalized code should be written in Python modules.\n",
    "\n",
    "## Object oriented programming?\n",
    "\n",
    "+ We can use classes to keep parameters and functions together.\n",
    "+ We *could* use Object Oriented Programming, but parallelization of data manipulation and modelling tasks benefits from *Functional Programming*.\n",
    "+ An Idea: \n",
    "\n",
    "    - [Data Oriented Programming](https://blog.klipse.tech/dop/2022/06/22/principles-of-dop.html).\n",
    "    - Use the class to bundle together parameters and functions.\n",
    "    - Use stateless operations and treat all data objects as immutable (we do not modify them, we overwrite them).\n",
    "    - Take advantage of [`@staticmethod`](https://realpython.com/instance-class-and-static-methods-demystified/).\n",
    "\n",
    "The code is in `./05_src/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our original design was:\n",
    "\n",
    "![](./images/02_target_pipeline_manager.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we demonstrate how our class implementation works.\n",
    "\n",
    "Before we begin, clean the price directory (we will download everything again)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLean up before start\n",
    "\n",
    "if os.path.exists(PRICE_DATA):\n",
    "    shutil.rmtree(PRICE_DATA)\n",
    "if os.path.exists(FEATURES_DATA):\n",
    "    shutil.rmtree(FEATURES_DATA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instantiate a DataManager object and download all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_manager import DataManager\n",
    "dm = DataManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dm.download_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, add features to our data set and save to a *feature store*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.featurize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
